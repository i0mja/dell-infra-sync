# OnboardZfsTargetWizard Enhancement Plan

> **Document ID:** 081225_plan_1
> **Created:** 2025-12-08
> **Status:** IN_PROGRESS
> **Current Phase:** 6

---

## QUICK REFERENCE

```
NEXT_ACTION: Implement Phase 7 - UX Polish (Recovery, debugging features)
BLOCKED_BY: None
FILES_TO_CREATE: None
FILES_TO_MODIFY: src/components/replication/OnboardZfsTargetWizard.tsx
```

---

## PHASE STATUS TRACKER

| Phase | Priority | Status | Description |
|-------|----------|--------|-------------|
| 1 | CRITICAL | ✅ COMPLETE | VMCombobox - Fix 1600+ VM selector |
| 2 | CRITICAL | ✅ COMPLETE | Backend Handler - `execute_onboard_zfs_target` |
| 3 | HIGH | ✅ COMPLETE | Enhanced Step 1 - VM preview, duplicate warning, OS check |
| 4 | HIGH | ✅ COMPLETE | Enhanced Auth - SSH key picker, test button |
| 5 | MEDIUM | ✅ COMPLETE | Enhanced Config - Disk picker, ZFS options, collapsible sections |
| 6 | MEDIUM | ✅ COMPLETE | Enhanced Finish - Protection group, schedule, summary card |
| 7 | LOW | ⏳ PENDING | UX Polish - Re-run failed, export log, rollback |

---

## EXISTING INFRASTRUCTURE

### ✅ Already Implemented
- `useSshKeys.ts` - Full CRUD for SSH keys with encryption
- `useVCenterVMs.ts` - Fetches VMs from vcenter_vms table
- `ssh_keys` table - Stores encrypted SSH keypairs
- `idrac_commands` logging with `ssh_command` operation type
- `execute_validate_zfs_template` handler
- `execute_prepare_zfs_template` handler  
- `execute_deploy_zfs_target` handler

### ❌ Missing Components
- `VMCombobox.tsx` - Searchable VM picker for 1600+ VMs
- `execute_onboard_zfs_target` handler - Unified wizard backend

---

## PHASE 1: VMCombobox (CRITICAL)

### Goal
Replace broken `<Select>` with searchable combobox that handles 1600+ VMs efficiently.

### Files

| File | Action |
|------|--------|
| `src/components/replication/VMCombobox.tsx` | CREATE |
| `src/components/replication/OnboardZfsTargetWizard.tsx` | MODIFY |
| `src/hooks/useVCenterVMs.ts` | MODIFY |

### Implementation Details

#### VMCombobox.tsx Features
```typescript
// Required features:
// 1. Fuzzy search input (using cmdk Command component)
// 2. Cluster filter dropdown
// 3. Power state filter (All / On / Off / Template)
// 4. Result count display ("Showing 42 of 1,623 VMs")
// 5. Compact VM cards with OS, specs, IP preview
// 6. Keyboard navigation
// 7. Virtualized list for performance (optional Phase 7)
```

#### Component Props
```typescript
interface VMComboboxProps {
  vcenterId: string;
  selectedVmId: string | null;
  onSelectVm: (vmId: string, vmName: string, vmIp: string | null) => void;
  disabled?: boolean;
}
```

#### useVCenterVMs.ts Modifications
```typescript
// Add to return:
// - clusters: string[] - Unique cluster names for filter
// - Filter function for power state
// - Search function for fuzzy matching
```

### Verification Checklist
- [ ] Can search VMs by name
- [ ] Can filter by cluster
- [ ] Can filter by power state
- [ ] Shows result count
- [ ] Keyboard navigation works
- [ ] Selected VM shows in trigger
- [ ] No performance issues with 1600+ VMs

---

## PHASE 2: Backend Handler (CRITICAL)

### Goal
Implement `execute_onboard_zfs_target` handler that processes the `onboard_zfs_target` job type.

### Files

| File | Action |
|------|--------|
| `job_executor/handlers/zfs_target.py` | MODIFY |

### Implementation Details

#### Handler Flow
```python
def execute_onboard_zfs_target(self, job: Dict) -> Dict:
    """
    Unified onboarding handler for ZFS replication targets.
    
    Steps:
    1. DETECT_VM_STATE - Check if VM exists, powered on, has IP
    2. SSH_AUTH - Connect via SSH (password or key)
    3. INSTALL_PACKAGES - apt-get install zfsutils-linux nfs-kernel-server
    4. CREATE_ZPOOL - zpool create with specified disk
    5. CONFIGURE_NFS - Set up NFS exports
    6. REGISTER_DATASTORE - Register NFS datastore in vCenter
    7. CREATE_TARGET - Insert into replication_targets table
    8. (Optional) CREATE_PROTECTION_GROUP - If user selected
    """
```

#### Job Details Schema
```python
details = {
    "vcenter_id": str,           # Source vCenter
    "vm_id": str,                # vcenter_vms.id
    "vm_moref": str,             # vm-123
    "vm_name": str,
    "vm_ip": str,
    "target_name": str,          # User-specified name
    
    # Auth options
    "auth_method": "password" | "ssh_key",
    "root_password": str | None,  # Encrypted
    "ssh_key_id": str | None,     # Reference to ssh_keys table
    
    # Config options
    "install_packages": bool,
    "create_zpool": bool,
    "zpool_disk": str,            # e.g., "/dev/sdb"
    "zpool_name": str,            # e.g., "zfs-repl"
    "compression": "lz4" | "zstd" | "off",
    "configure_nfs": bool,
    "datastore_name": str,        # vCenter datastore name
    
    # Finish options
    "create_protection_group": bool,
    "protection_group_name": str | None,
    "add_vms_to_protect": str[] | None,  # VM IDs
    "replication_schedule": str | None,   # cron expression
    
    # Progress tracking
    "step_results": {
        "detect_vm_state": {"status": "success|failed|pending", "message": str},
        "ssh_auth": {...},
        "install_packages": {...},
        ...
    }
}
```

#### SSH Logging Integration
```python
# Use enhanced _ssh_exec() which already logs to idrac_commands
# with operation_type='ssh_command'
result = self._ssh_exec(command, job_id=job['id'])
```

### Verification Checklist
- [ ] Handler registered in job type dispatch
- [ ] All steps log to idrac_commands
- [ ] Step results saved to job.details
- [ ] Failure handling with rollback option
- [ ] Creates replication_target on success

---

## PHASE 3: Enhanced Step 1 (HIGH)

### Goal
Improve VM selection with preview and duplicate detection.

### Files

| File | Action |
|------|--------|
| `src/components/replication/OnboardZfsTargetWizard.tsx` | MODIFY |

### Features

1. **VM Preview Card**
```typescript
// Show after VM selection:
// - Guest OS (from vcenter_vms.guest_os)
// - CPU count, RAM
// - Current IP address
// - Power state badge
// - Cluster/Host location
```

2. **Duplicate Detection**
```typescript
// Query replication_targets where:
// - deployed_vm_moref matches selected VM
// - OR hostname matches VM IP
// Show warning: "This VM is already registered as target 'xyz'"
```

3. **OS Compatibility Check**
```typescript
// Check guest_os for Debian/Ubuntu
// Show warning if not: "This wizard requires Debian/Ubuntu. Detected: {os}"
```

### Verification Checklist
- [ ] Preview card shows after selection
- [ ] Duplicate warning appears if exists
- [ ] OS compatibility warning works
- [ ] Target name auto-populates from VM name

---

## PHASE 4: Enhanced Authentication (HIGH)

### Goal
Add SSH key selection and connection testing.

### Files

| File | Action |
|------|--------|
| `src/components/replication/OnboardZfsTargetWizard.tsx` | MODIFY |

### Features

1. **SSH Key Picker**
```typescript
// Use existing useSshKeys hook
// Dropdown: "Select existing SSH key" or "Use password"
// If key selected, show fingerprint
// "Generate New Key" button creates keypair
```

2. **Public Key Display**
```typescript
// If SSH key selected, show public key in copyable textarea
// Message: "Add this to ~/.ssh/authorized_keys on the target"
```

3. **Test Connection Button**
```typescript
// Before starting job, allow "Test SSH Connection"
// Creates job with job_type: 'test_ssh_connection'
// Shows success/failure inline
```

### Verification Checklist
- [ ] Can select existing SSH key
- [ ] Can generate new SSH key
- [ ] Public key is copyable
- [ ] Test connection works
- [ ] Password fallback works

---

## PHASE 5: Enhanced Configuration (MEDIUM)

### Goal
Add disk detection and ZFS options.

### Files

| File | Action |
|------|--------|
| `src/components/replication/OnboardZfsTargetWizard.tsx` | MODIFY |
| `job_executor/handlers/zfs_target.py` | MODIFY |

### Features

1. **Disk Picker**
```typescript
// After SSH connects, run: lsblk -J -o NAME,SIZE,TYPE,MOUNTPOINT
// Parse JSON, show available disks
// Filter out mounted disks
// Dropdown: "Select disk for ZFS pool"
```

2. **ZFS Options**
```typescript
// Compression: lz4 (default) | zstd | off
// Pool name: text input with validation
// Dataset path: auto-generated or custom
```

3. **NFS Options**
```typescript
// Export path: /zfs-repl/nfs (default)
// Allowed networks: auto-detect or custom CIDR
```

4. **vCenter Datastore Name**
```typescript
// Auto-generate from target name or custom
// Validate uniqueness in vCenter
```

### Verification Checklist
- [ ] Disk list populates after SSH
- [ ] Can select compression level
- [ ] Can customize pool/dataset names
- [ ] Datastore name validation works

---

## PHASE 6: Enhanced Finalization (MEDIUM)

### Goal
Add protection group creation and scheduling.

### Files

| File | Action |
|------|--------|
| `src/components/replication/OnboardZfsTargetWizard.tsx` | MODIFY |

### Features

1. **Protection Group Options**
```typescript
// Radio: "Create new protection group" | "Add to existing" | "Skip"
// If new: name input, description
// If existing: dropdown of protection_groups
```

2. **VM Selection for Protection**
```typescript
// Multi-select VMCombobox
// Show: "Select VMs to protect with this target"
// Limit to source vCenter VMs
```

3. **Replication Schedule**
```typescript
// Presets: Every 15 min | Hourly | Every 4 hours | Daily
// Custom: cron input
// RPO indicator based on selection
```

4. **Summary Card**
```typescript
// Before starting, show:
// - Target: {name} at {ip}
// - ZFS Pool: {pool_name} on {disk}
// - Datastore: {datastore_name}
// - Protection Group: {pg_name} with {n} VMs
// - Schedule: {schedule}
// - Estimated initial sync: {estimate}
```

### Verification Checklist
- [ ] Can create new protection group
- [ ] Can select existing protection group
- [ ] Can add VMs to protect
- [ ] Schedule picker works
- [ ] Summary shows all selections

---

## PHASE 7: UX Polish (LOW)

### Goal
Add recovery and debugging features.

### Files

| File | Action |
|------|--------|
| `src/components/replication/OnboardZfsTargetWizard.tsx` | MODIFY |

### Features

1. **Re-run Failed Steps**
```typescript
// If step fails, show "Retry" button
// Updates job.details to re-run from failed step
// Preserves successful step results
```

2. **Export Console Log**
```typescript
// Button: "Export Log"
// Downloads job.details.console_log as .txt
// Includes timestamps and step markers
```

3. **Rollback Option**
```typescript
// If job fails, offer "Clean Up"
// - Delete partially created zpool
// - Remove NFS exports
// - Unregister datastore
// - Delete replication_target record
```

4. **Virtualized VM List**
```typescript
// For VMCombobox, add react-window or tanstack-virtual
// Renders only visible items for 1600+ VMs
```

### Verification Checklist
- [ ] Retry button works for failed steps
- [ ] Export produces valid log file
- [ ] Rollback cleans up properly
- [ ] VM list performs well at scale

---

## CODE TEMPLATES

### VMCombobox Component Structure
```typescript
// src/components/replication/VMCombobox.tsx
import { useState, useMemo } from 'react';
import { Command, CommandInput, CommandList, CommandEmpty, CommandGroup, CommandItem } from '@/components/ui/command';
import { Popover, PopoverContent, PopoverTrigger } from '@/components/ui/popover';
import { Button } from '@/components/ui/button';
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from '@/components/ui/select';
import { Badge } from '@/components/ui/badge';
import { Check, ChevronsUpDown, Server, Power, PowerOff } from 'lucide-react';
import { cn } from '@/lib/utils';

interface VM {
  id: string;
  name: string;
  guest_ip: string | null;
  power_state: string;
  cluster_name: string | null;
  guest_os: string | null;
  num_cpu: number | null;
  memory_mb: number | null;
}

interface VMComboboxProps {
  vms: VM[];
  clusters: string[];
  selectedVmId: string | null;
  onSelectVm: (vm: VM) => void;
  disabled?: boolean;
  isLoading?: boolean;
}

export function VMCombobox({ vms, clusters, selectedVmId, onSelectVm, disabled, isLoading }: VMComboboxProps) {
  const [open, setOpen] = useState(false);
  const [search, setSearch] = useState('');
  const [clusterFilter, setClusterFilter] = useState<string>('all');
  const [powerFilter, setPowerFilter] = useState<string>('all');

  const filteredVMs = useMemo(() => {
    return vms.filter(vm => {
      const matchesSearch = vm.name.toLowerCase().includes(search.toLowerCase());
      const matchesCluster = clusterFilter === 'all' || vm.cluster_name === clusterFilter;
      const matchesPower = powerFilter === 'all' || vm.power_state === powerFilter;
      return matchesSearch && matchesCluster && matchesPower;
    });
  }, [vms, search, clusterFilter, powerFilter]);

  const selectedVM = vms.find(vm => vm.id === selectedVmId);

  return (
    <div className="space-y-2">
      {/* Filter row */}
      <div className="flex gap-2">
        <Select value={clusterFilter} onValueChange={setClusterFilter}>
          <SelectTrigger className="w-[180px]">
            <SelectValue placeholder="All Clusters" />
          </SelectTrigger>
          <SelectContent>
            <SelectItem value="all">All Clusters</SelectItem>
            {clusters.map(c => <SelectItem key={c} value={c}>{c}</SelectItem>)}
          </SelectContent>
        </Select>
        
        <Select value={powerFilter} onValueChange={setPowerFilter}>
          <SelectTrigger className="w-[140px]">
            <SelectValue placeholder="Power State" />
          </SelectTrigger>
          <SelectContent>
            <SelectItem value="all">All States</SelectItem>
            <SelectItem value="poweredOn">Powered On</SelectItem>
            <SelectItem value="poweredOff">Powered Off</SelectItem>
          </SelectContent>
        </Select>
      </div>

      {/* Combobox */}
      <Popover open={open} onOpenChange={setOpen}>
        <PopoverTrigger asChild>
          <Button
            variant="outline"
            role="combobox"
            aria-expanded={open}
            className="w-full justify-between"
            disabled={disabled || isLoading}
          >
            {selectedVM ? (
              <span className="flex items-center gap-2">
                <Server className="h-4 w-4" />
                {selectedVM.name}
                {selectedVM.guest_ip && <span className="text-muted-foreground">({selectedVM.guest_ip})</span>}
              </span>
            ) : (
              "Select a VM..."
            )}
            <ChevronsUpDown className="ml-2 h-4 w-4 shrink-0 opacity-50" />
          </Button>
        </PopoverTrigger>
        <PopoverContent className="w-[500px] p-0" align="start">
          <Command shouldFilter={false}>
            <CommandInput 
              placeholder="Search VMs..." 
              value={search}
              onValueChange={setSearch}
            />
            <div className="px-2 py-1.5 text-xs text-muted-foreground">
              Showing {filteredVMs.length} of {vms.length} VMs
            </div>
            <CommandList className="max-h-[300px]">
              <CommandEmpty>No VMs found.</CommandEmpty>
              <CommandGroup>
                {filteredVMs.slice(0, 100).map(vm => (
                  <CommandItem
                    key={vm.id}
                    value={vm.id}
                    onSelect={() => {
                      onSelectVm(vm);
                      setOpen(false);
                    }}
                  >
                    <Check className={cn("mr-2 h-4 w-4", selectedVmId === vm.id ? "opacity-100" : "opacity-0")} />
                    <div className="flex-1 flex items-center gap-2">
                      {vm.power_state === 'poweredOn' ? (
                        <Power className="h-3 w-3 text-green-500" />
                      ) : (
                        <PowerOff className="h-3 w-3 text-muted-foreground" />
                      )}
                      <span>{vm.name}</span>
                      {vm.guest_ip && <span className="text-muted-foreground text-xs">({vm.guest_ip})</span>}
                    </div>
                    {vm.cluster_name && (
                      <Badge variant="outline" className="text-xs">{vm.cluster_name}</Badge>
                    )}
                  </CommandItem>
                ))}
              </CommandGroup>
            </CommandList>
          </Command>
        </PopoverContent>
      </Popover>
    </div>
  );
}
```

### Backend Handler Template
```python
# job_executor/handlers/zfs_target.py - add to ZfsTargetHandler class

def execute_onboard_zfs_target(self, job: Dict) -> Dict:
    """
    Unified onboarding handler for ZFS replication targets.
    Consolidates prepare + deploy into single wizard flow.
    """
    job_id = job['id']
    details = job.get('details', {})
    
    # Initialize step tracking
    step_results = details.get('step_results', {})
    
    try:
        # Step 1: Detect VM State
        step_results['detect_vm_state'] = {'status': 'running'}
        self._update_job_details(job_id, {'step_results': step_results})
        
        vm_state = self._detect_vm_state(details)
        step_results['detect_vm_state'] = {'status': 'success', 'data': vm_state}
        
        # Step 2: SSH Authentication
        step_results['ssh_auth'] = {'status': 'running'}
        self._update_job_details(job_id, {'step_results': step_results})
        
        ssh_result = self._establish_ssh(details, job_id)
        step_results['ssh_auth'] = {'status': 'success' if ssh_result['success'] else 'failed', 
                                     'message': ssh_result.get('message')}
        
        if not ssh_result['success']:
            # Check if password needed
            if ssh_result.get('needs_password'):
                step_results['ssh_auth']['needs_password'] = True
                self._update_job_details(job_id, {'step_results': step_results})
                return {'status': 'waiting_for_input', 'step': 'ssh_auth'}
            raise Exception(ssh_result['message'])
        
        # Step 3: Install Packages (if enabled)
        if details.get('install_packages', True):
            step_results['install_packages'] = {'status': 'running'}
            self._update_job_details(job_id, {'step_results': step_results})
            
            pkg_result = self._install_zfs_packages(job_id)
            step_results['install_packages'] = {
                'status': 'success' if pkg_result['success'] else 'failed',
                'message': pkg_result.get('message')
            }
        
        # Step 4: Create ZFS Pool (if enabled)
        if details.get('create_zpool', True):
            step_results['create_zpool'] = {'status': 'running'}
            self._update_job_details(job_id, {'step_results': step_results})
            
            zpool_result = self._create_zpool(
                disk=details.get('zpool_disk', '/dev/sdb'),
                pool_name=details.get('zpool_name', 'zfs-repl'),
                compression=details.get('compression', 'lz4'),
                job_id=job_id
            )
            step_results['create_zpool'] = {
                'status': 'success' if zpool_result['success'] else 'failed',
                'message': zpool_result.get('message')
            }
        
        # Step 5: Configure NFS
        if details.get('configure_nfs', True):
            step_results['configure_nfs'] = {'status': 'running'}
            self._update_job_details(job_id, {'step_results': step_results})
            
            nfs_result = self._configure_nfs(
                pool_name=details.get('zpool_name', 'zfs-repl'),
                job_id=job_id
            )
            step_results['configure_nfs'] = {
                'status': 'success' if nfs_result['success'] else 'failed',
                'message': nfs_result.get('message')
            }
        
        # Step 6: Register vCenter Datastore
        step_results['register_datastore'] = {'status': 'running'}
        self._update_job_details(job_id, {'step_results': step_results})
        
        ds_result = self._register_nfs_datastore(
            vcenter_id=details['vcenter_id'],
            datastore_name=details.get('datastore_name', f"ZFS-{details['target_name']}"),
            nfs_host=details['vm_ip'],
            nfs_path=f"/{details.get('zpool_name', 'zfs-repl')}/nfs",
            job_id=job_id
        )
        step_results['register_datastore'] = {
            'status': 'success' if ds_result['success'] else 'failed',
            'message': ds_result.get('message')
        }
        
        # Step 7: Create Replication Target
        step_results['create_target'] = {'status': 'running'}
        self._update_job_details(job_id, {'step_results': step_results})
        
        target_result = self._create_replication_target(details, job_id)
        step_results['create_target'] = {
            'status': 'success',
            'target_id': target_result['target_id']
        }
        
        # Step 8: Create Protection Group (optional)
        if details.get('create_protection_group'):
            step_results['create_protection_group'] = {'status': 'running'}
            self._update_job_details(job_id, {'step_results': step_results})
            
            pg_result = self._create_protection_group(
                name=details.get('protection_group_name'),
                target_id=target_result['target_id'],
                vm_ids=details.get('add_vms_to_protect', []),
                schedule=details.get('replication_schedule'),
                job_id=job_id
            )
            step_results['create_protection_group'] = {
                'status': 'success',
                'protection_group_id': pg_result['id']
            }
        
        # Final update
        self._update_job_details(job_id, {'step_results': step_results})
        
        return {
            'status': 'completed',
            'target_id': target_result['target_id'],
            'step_results': step_results
        }
        
    except Exception as e:
        self.logger.error(f"Onboard ZFS target failed: {e}")
        # Mark current step as failed
        for step, result in step_results.items():
            if result.get('status') == 'running':
                step_results[step] = {'status': 'failed', 'message': str(e)}
        self._update_job_details(job_id, {'step_results': step_results})
        raise
```

---

## DEPENDENCY GRAPH

```
Phase 1 (VMCombobox) ─────────────────────────────────────────┐
                                                               │
Phase 2 (Backend Handler) ────────────────────────────────────┼──► Phase 3 (Step 1 Enhancements)
                                                               │
                                                               ├──► Phase 4 (Auth Enhancements)
                                                               │
                                                               ├──► Phase 5 (Config Enhancements)
                                                               │
                                                               └──► Phase 6 (Finish Enhancements)
                                                                              │
                                                                              ▼
                                                                    Phase 7 (UX Polish)
```

---

## LLM INSTRUCTIONS

When continuing this plan, use the following format:

```
## Starting Phase X: [Phase Name]

### Reading Required Files
[List files to read]

### Implementation
[Code changes]

### Verification
[How to test]

### Updating Plan Status
After completion, update docs/081225_plan_1.md:
- Change Phase X status from ⏳ PENDING to ✅ COMPLETE
- Update NEXT_ACTION in QUICK REFERENCE
```

---

## NOTES

- SSH command logging already implemented (operation_type='ssh_command')
- useSshKeys hook already exists at src/hooks/useSshKeys.ts
- useVCenterVMs hook exists but may need cluster extraction
- OnboardZfsTargetWizard.tsx is at lines 1-842 (large file, consider refactoring)
